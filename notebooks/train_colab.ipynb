{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# tradingagent — Walk-Forward Backtest (Colab GPU)\n\nRun the full 4-layer screener backtest with **GPU-accelerated XGBoost** on Colab.\n\n**Prerequisites:**\n- Upload `data/ohlcv_all_a.pkl` and `data/benchmark_000905.pkl` to your Google Drive under `MyDrive/kronos/data/`.\n- Or adjust the paths in the Config cell below.\n\n**Runtime:** Select *Runtime → Change runtime type → T4 GPU*."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 1: Setup — install dependencies and mount Drive\nfrom google.colab import drive\ndrive.mount('/content/drive')\n\nimport os\nDRIVE_ROOT = '/content/drive/MyDrive/kronos'\nos.makedirs(DRIVE_ROOT, exist_ok=True)\nprint(f'Drive root: {DRIVE_ROOT}')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 2: Clone/update repo, install deps, add to path\nimport sys\n\nREPO_DIR = '/content/tradingagent'\n\nif not os.path.exists(REPO_DIR):\n    !git clone https://github.com/Yuxiaoliu12/tradingagent.git {REPO_DIR}\nelse:\n    !cd {REPO_DIR} && git pull origin main\n\n!pip install -q -r {REPO_DIR}/requirements.txt\n\nsys.path.insert(0, REPO_DIR)\nprint(f'Repo at: {REPO_DIR}')\nprint(f'sys.path[0]: {sys.path[0]}')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 3: Config — GPU XGBoost override\nfrom screener.config import ScreenerConfig\n\ncfg = ScreenerConfig(\n    ohlcv_pickle_path=os.path.join(DRIVE_ROOT, 'data/ohlcv_all_a.pkl'),\n    benchmark_pickle_path=os.path.join(DRIVE_ROOT, 'data/benchmark_000905.pkl'),\n    industry_pickle_path=os.path.join(DRIVE_ROOT, 'data/industry_mapping.pkl'),\n    drive_root=os.path.join(DRIVE_ROOT, 'output/screener'),\n)\n\n# Enable GPU for XGBoost (Colab T4)\ncfg.layer1_xgb_params['device'] = 'cuda'\ncfg.layer2_xgb_params['device'] = 'cuda'\n\nprint('XGBoost device (Layer 1):', cfg.layer1_xgb_params.get('device'))\nprint('XGBoost device (Layer 2):', cfg.layer2_xgb_params.get('device'))\nprint(f'Train: {cfg.train_start} → {cfg.train_end}')\nprint(f'Backtest: {cfg.backtest_start} → {cfg.backtest_end}')\nprint(f'Run ID: {cfg.run_id}')\nprint(f'Run dir: {cfg.run_dir}')\nprint(f'Cache dir: {cfg.cache_dir}')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## RL Portfolio Agent (Layer 4)\n\nTrain a MaskablePPO agent on the same walk-forward windows. Uses L1+L2 signals as observations, manages a 3-stock portfolio with discrete position sizing, open/close execution timing, and action masking for A-share constraints.\n\n**Workflow:** Run Cells 1-3 first (setup + config), then precompute L1+L2 signals below, then train/ablate."
  },
  {
   "cell_type": "code",
   "source": "# Cell 4: Precompute L1+L2 signals (run once, cached to Drive)\n# After this, run_rl() loads cached signals and skips L1+L2 entirely.\nimport time\nfrom screener.backtester import WalkForwardBacktester\n\nbt = WalkForwardBacktester(cfg)\n\nt0 = time.time()\nbt.precompute_signals(verbose=True)\nprint(f'\\nPrecompute wall time: {(time.time() - t0)/60:.1f} min')",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 6: RL Smoke Test — verify env + PPO work before full run\n# Uses synthetic signals (no L1+L2 needed). Should finish in <30 seconds.\n\nimport numpy as np\nimport pandas as pd\n\n# ── 1. Action table ──────────────────────────────────────────────\nfrom screener.portfolio_env import build_action_table, PortfolioEnv\nactions = build_action_table(3, 3)\nassert len(actions) == 63, f\"Expected 63 actions, got {len(actions)}\"\nfor a in actions:\n    assert a[0] + a[1] + a[2] <= 1.0 + 1e-9, f\"Weights exceed 1: {a}\"\nprint(f\"[OK] Action table: {len(actions)} actions, all weights sum <= 1\")\n\n# ── 2. Build synthetic env ───────────────────────────────────────\n# 100 trading days, 50 fake stocks with random OHLCV\nnp.random.seed(42)\nn_days, n_stocks = 100, 50\ndates = pd.bdate_range(\"2020-01-01\", periods=n_days)\n\nohlcv_dict = {}\nfor i in range(n_stocks):\n    sym = f\"sh.{600000+i}\"\n    close = 10.0 * np.exp(np.cumsum(np.random.randn(n_days) * 0.02))\n    df = pd.DataFrame({\n        \"open\": close * (1 + np.random.randn(n_days) * 0.005),\n        \"high\": close * (1 + abs(np.random.randn(n_days) * 0.01)),\n        \"low\":  close * (1 - abs(np.random.randn(n_days) * 0.01)),\n        \"close\": close,\n        \"volume\": np.random.randint(1000, 100000, n_days).astype(float),\n    }, index=dates)\n    ohlcv_dict[sym] = df\n\nsymbols = list(ohlcv_dict.keys())\nbench_df = pd.DataFrame({\"close\": np.linspace(100, 110, n_days)}, index=dates)\n\n# Fake daily signals: random L2 scores + upside/downside + features\ndaily_signals = []\nfor d in dates:\n    upside = pd.Series(np.abs(np.random.randn(n_stocks)) * 0.05, index=symbols)\n    downside = pd.Series(-np.abs(np.random.randn(n_stocks)) * 0.05, index=symbols)\n    combined = upside + downside\n    feats = pd.DataFrame(\n        np.random.randn(n_stocks, 16),\n        index=symbols,\n        columns=[\n            \"macd\", \"macd_signal\", \"macd_hist\", \"rsi_14\", \"rsi_5\",\n            \"ma5_slope\", \"ma20_slope\", \"ma60_slope\", \"bb_position\",\n            \"volume_trend\", \"mom_5\", \"mom_10\", \"mom_20\", \"atr_14\", \"obv_slope\",\n            \"industry_code\",\n        ],\n    )\n    # Industry code should be integers, not floats\n    feats[\"industry_code\"] = np.random.randint(0, 20, n_stocks)\n    daily_signals.append({\n        \"date\": d,\n        \"l2_scores\": combined.sort_values(ascending=False),\n        \"l2_upside\": upside,\n        \"l2_downside\": downside,\n        \"l2_ranking\": list(combined.sort_values(ascending=False).index),\n        \"l2_features\": feats,\n    })\n\nfrom screener.config import ScreenerConfig\nsmoke_cfg = ScreenerConfig()\n\n# ── 3. Env smoke test: random steps ─────────────────────────────\nenv = PortfolioEnv(smoke_cfg, daily_signals, ohlcv_dict, bench_df, training_mode=True)\nobs, info = env.reset()\nassert obs.shape == (40,), f\"Obs shape: {obs.shape}\"\nassert not np.any(np.isnan(obs)), \"NaN in initial obs\"\n\ntotal_reward = 0.0\nfor step in range(n_days - 1):\n    action = env.action_space.sample()\n    obs, reward, terminated, truncated, info = env.step(action)\n    assert obs.shape == (40,), f\"Step {step}: obs shape {obs.shape}\"\n    assert not np.any(np.isnan(obs)), f\"Step {step}: NaN in obs\"\n    total_reward += reward\n    if terminated:\n        break\n\nfinal_nav = env._nav\nprint(f\"[OK] Random agent: {step+1} steps, final NAV={final_nav:,.0f} \"\n      f\"(return={final_nav/smoke_cfg.initial_capital - 1:+.2%}), \"\n      f\"total reward={total_reward:.2f}\")\nassert final_nav > 0, \"NAV went to zero\"\n\n# ── 4. Action mask sanity ────────────────────────────────────────\nenv2 = PortfolioEnv(smoke_cfg, daily_signals, ohlcv_dict, bench_df, training_mode=False)\nobs2, _ = env2.reset()\nmask = env2.action_masks()\nassert mask.shape == (63,) and mask.dtype == bool and mask.any()\nprint(f\"[OK] Action masks: {mask.sum()}/63 legal, {(~mask).sum()} masked (day 0)\")\n\n# ── 5. PPO smoke test: train 1000 steps ─────────────────────────\nfrom screener.rl_trader import RLTrader\n\nsmoke_cfg_ppo = ScreenerConfig(\n    rl_total_timesteps=1000,\n    rl_batch_size=32,\n    rl_n_steps=128,\n)\ntrain_env = PortfolioEnv(smoke_cfg_ppo, daily_signals, ohlcv_dict, bench_df, training_mode=True)\ntrader = RLTrader(smoke_cfg_ppo)\nmodel = trader.train(train_env)\n\n# Test inference with masks\nfrom sb3_contrib.common.wrappers import ActionMasker\nfrom sb3_contrib.common.maskable.utils import get_action_masks\n\ntest_env = PortfolioEnv(smoke_cfg_ppo, daily_signals, ohlcv_dict, bench_df, training_mode=False)\nmasked_test_env = ActionMasker(test_env, lambda e: e.action_masks())\nobs, _ = masked_test_env.reset()\nblocked = 0\nfor _ in range(20):\n    masks = get_action_masks(masked_test_env)\n    action, _ = model.predict(obs, deterministic=True, action_masks=masks)\n    obs, reward, terminated, truncated, info = masked_test_env.step(int(action))\n    blocked += len(info.get(\"blocked_trades\", []))\n    if terminated:\n        break\nprint(f\"[OK] PPO inference: 20 steps, NAV={test_env._nav:,.0f}, blocked={blocked}\")\n\n# Save/load round-trip\nimport tempfile, os\nwith tempfile.TemporaryDirectory() as tmpdir:\n    path = os.path.join(tmpdir, \"smoke_model\")\n    trader.save(model, path)\n    loaded = trader.load(path)\n    obs_test, _ = masked_test_env.reset()\n    masks_test = get_action_masks(masked_test_env)\n    a1, _ = model.predict(obs_test, deterministic=True, action_masks=masks_test)\n    a2, _ = loaded.predict(obs_test, deterministic=True, action_masks=masks_test)\n    assert a1 == a2, \"Loaded model gives different action\"\nprint(\"[OK] Model save/load round-trip\")\n\nprint(\"\\n=== All smoke tests passed ===\")"
  },
  {
   "cell_type": "code",
   "source": "# Cell 6b: Illegal-Action & Buy-Fallback Tests\n# Verifies A-share constraints and L2 fallback behaviour with synthetic OHLCV.\n# Should finish in <5 seconds.\n\nimport numpy as np\nimport pandas as pd\nfrom screener.config import ScreenerConfig\nfrom screener.portfolio_env import PortfolioEnv, build_action_table\n\ntest_cfg = ScreenerConfig()\ndates = pd.bdate_range(\"2020-01-01\", periods=10)\n\ndef _make_ohlcv(dates, close_vals, open_vals=None, volume_vals=None):\n    \"\"\"Helper: build a simple OHLCV DataFrame.\"\"\"\n    n = len(dates)\n    close = np.array(close_vals, dtype=float)\n    opn = np.array(open_vals if open_vals else close_vals, dtype=float)\n    vol = np.array(volume_vals if volume_vals else [10000.0] * n, dtype=float)\n    return pd.DataFrame({\n        \"open\": opn, \"high\": np.maximum(opn, close) * 1.001,\n        \"low\": np.minimum(opn, close) * 0.999,\n        \"close\": close, \"volume\": vol,\n    }, index=dates)\n\n# ── Shared L2 feature columns ────────────────────────────────────\n_feat_cols = [\n    \"macd\", \"macd_signal\", \"macd_hist\", \"rsi_14\", \"rsi_5\",\n    \"ma5_slope\", \"ma20_slope\", \"ma60_slope\", \"bb_position\",\n    \"volume_trend\", \"mom_5\", \"mom_10\", \"mom_20\", \"atr_14\", \"obv_slope\",\n    \"industry_code\",\n]\n\ndef _make_signals(dates, symbols, ranking=None):\n    \"\"\"Build daily signals with fixed ranking order.\"\"\"\n    sigs = []\n    for d in dates:\n        scores = pd.Series(\n            np.linspace(1, 0, len(symbols)), index=symbols\n        )\n        if ranking:\n            scores = pd.Series(\n                np.linspace(1, 0, len(ranking)), index=ranking\n            )\n        upside = pd.Series(\n            np.linspace(0.5, 0, len(scores)), index=scores.index\n        )\n        downside = pd.Series(\n            np.linspace(-0.1, -0.5, len(scores)), index=scores.index\n        )\n        feats = pd.DataFrame(\n            np.zeros((len(scores), len(_feat_cols))),\n            index=scores.index, columns=_feat_cols,\n        )\n        sigs.append({\n            \"date\": d,\n            \"l2_scores\": scores.sort_values(ascending=False),\n            \"l2_upside\": upside,\n            \"l2_downside\": downside,\n            \"l2_ranking\": list(scores.sort_values(ascending=False).index),\n            \"l2_features\": feats,\n        })\n    return sigs\n\nbench_df = pd.DataFrame({\"close\": np.linspace(100, 110, len(dates))}, index=dates)\n\n# ══════════════════════════════════════════════════════════════════\n# BUY-SIDE TESTS: fallback when primary stock is blocked\n# ══════════════════════════════════════════════════════════════════\nprint(\"=\" * 60)\nprint(\"BUY-SIDE FALLBACK TESTS\")\nprint(\"=\" * 60)\n\n# Stock A: limit-up at open on day 1 → blocked\n# Stock B: normal → fallback target\n# Ranking: A first, B second\nprev_close_a = 10.0\nlimit_up_open_a = prev_close_a * 1.10  # exactly +10%\nohlcv_a = _make_ohlcv(\n    dates,\n    close_vals=[prev_close_a] + [limit_up_open_a] * 9,\n    open_vals=[prev_close_a] + [limit_up_open_a] * 9,\n)\nohlcv_b = _make_ohlcv(dates, close_vals=[10.0] * 10)\nohlcv_dict_buy1 = {\"sh.600001\": ohlcv_a, \"sh.600002\": ohlcv_b}\nranking = [\"sh.600001\", \"sh.600002\"]\nsigs = _make_signals(dates, ranking, ranking=ranking)\n\nenv = PortfolioEnv(test_cfg, sigs, ohlcv_dict_buy1, bench_df, training_mode=False)\nobs, _ = env.reset()\n\n# Action: put 1/3 weight on slot 0 (stock A), open timing\n# Slot 0 should be sh.600001 (top ranked), slot 1 = sh.600002\naction_table = build_action_table(3, 3)\n# Find action: (1/3, 0, 0, \"open\", None, None)\nact_idx = None\nfor i, a in enumerate(action_table):\n    if a[:3] == (1/3, 0, 0) and a[3] == \"open\":\n        act_idx = i\n        break\nassert act_idx is not None, \"Could not find target action\"\n\nobs, reward, term, trunc, info = env.step(act_idx)\nblocked = info.get(\"blocked_trades\", [])\nsubs = info.get(\"substituted_trades\", [])\nassert len(subs) == 1, f\"Expected 1 substitution, got {len(subs)}: {subs}\"\nassert subs[0][\"slot_symbol\"] == \"sh.600001\", f\"Wrong slot sym: {subs[0]}\"\nassert subs[0][\"bought_symbol\"] == \"sh.600002\", f\"Wrong bought sym: {subs[0]}\"\nassert \"sh.600002\" in env._holdings, \"Fallback stock not in holdings\"\nassert \"sh.600001\" not in env._holdings, \"Blocked stock should not be in holdings\"\nprint(f\"[OK] Limit-up fallback: A blocked, B bought. subs={subs}\")\n\n# Stock C: suspended (volume=0) → fallback to Stock D\nohlcv_c = _make_ohlcv(dates, close_vals=[10.0] * 10, volume_vals=[10000] + [0] * 9)\nohlcv_d = _make_ohlcv(dates, close_vals=[10.0] * 10)\nohlcv_dict_buy2 = {\"sh.600003\": ohlcv_c, \"sh.600004\": ohlcv_d}\nranking2 = [\"sh.600003\", \"sh.600004\"]\nsigs2 = _make_signals(dates, ranking2, ranking=ranking2)\n\nenv2 = PortfolioEnv(test_cfg, sigs2, ohlcv_dict_buy2, bench_df, training_mode=False)\nobs2, _ = env2.reset()\nobs2, _, _, _, info2 = env2.step(act_idx)\nsubs2 = info2.get(\"substituted_trades\", [])\nassert len(subs2) == 1, f\"Expected 1 sub (suspension), got {len(subs2)}\"\nassert subs2[0][\"bought_symbol\"] == \"sh.600004\"\nassert \"sh.600004\" in env2._holdings\nprint(f\"[OK] Suspension fallback: C blocked (vol=0), D bought. subs={subs2}\")\n\n# Stock E: 一字板 at limit-up (O=H=L=C = prev_close * 1.10) → fallback to F\nprev_close_e = 10.0\nyizi_price = prev_close_e * 1.10\nohlcv_e = _make_ohlcv(\n    dates,\n    close_vals=[prev_close_e] + [yizi_price] * 9,\n    open_vals=[prev_close_e] + [yizi_price] * 9,\n)\n# Force O=H=L=C for 一字板\nfor col in [\"open\", \"high\", \"low\", \"close\"]:\n    ohlcv_e.iloc[1:, ohlcv_e.columns.get_loc(col)] = yizi_price\n\nohlcv_f = _make_ohlcv(dates, close_vals=[10.0] * 10)\nohlcv_dict_buy3 = {\"sh.600005\": ohlcv_e, \"sh.600006\": ohlcv_f}\nranking3 = [\"sh.600005\", \"sh.600006\"]\nsigs3 = _make_signals(dates, ranking3, ranking=ranking3)\n\nenv3 = PortfolioEnv(test_cfg, sigs3, ohlcv_dict_buy3, bench_df, training_mode=False)\nobs3, _ = env3.reset()\nobs3, _, _, _, info3 = env3.step(act_idx)\nsubs3 = info3.get(\"substituted_trades\", [])\nassert len(subs3) == 1, f\"Expected 1 sub (一字板), got {len(subs3)}\"\nassert subs3[0][\"bought_symbol\"] == \"sh.600006\"\nprint(f\"[OK] 一字板 limit-up fallback: E blocked, F bought. subs={subs3}\")\n\n# ══════════════════════════════════════════════════════════════════\n# SELL-SIDE TESTS: blocked sells keep position\n# ══════════════════════════════════════════════════════════════════\nprint(\"\\n\" + \"=\" * 60)\nprint(\"SELL-SIDE BLOCKING TESTS\")\nprint(\"=\" * 60)\n\n# Find action: sell slot 0 (weight=0) with any timing\nsell_act_idx = None\nfor i, a in enumerate(action_table):\n    if a[:3] == (0, 0, 0):\n        sell_act_idx = i\n        break\nassert sell_act_idx is not None\n\n# Helper to set up an env with a held stock, then try to sell on day 2\ndef _sell_test(ohlcv_dict, sym, description):\n    ranking = list(ohlcv_dict.keys())\n    sigs = _make_signals(dates, ranking, ranking=ranking)\n    env = PortfolioEnv(test_cfg, sigs, ohlcv_dict, bench_df, training_mode=False)\n    obs, _ = env.reset()\n\n    # Step 1: buy the stock (put 1/3 on slot 0)\n    obs, _, _, _, info1 = env.step(act_idx)\n    assert sym in env._holdings, f\"Failed to buy {sym} on step 1\"\n    shares_before = env._holdings[sym][\"shares\"]\n\n    # Step 2: try to sell (weight=0 on all slots → sell everything)\n    obs, _, _, _, info2 = env.step(sell_act_idx)\n\n    # T+1: hold_days was 0 after buy, incremented to 1 at step start,\n    # so _can_sell should pass T+1. The constraint check tests the\n    # specific sell-blocking scenario.\n    return env, info2, shares_before\n\n# Test: limit-down at open blocks sell\nprev_close_g = 10.0\nlimit_down_price = prev_close_g * 0.90\nohlcv_g = _make_ohlcv(\n    dates,\n    close_vals=[prev_close_g, prev_close_g, limit_down_price] + [limit_down_price] * 7,\n    open_vals=[prev_close_g, prev_close_g, limit_down_price] + [limit_down_price] * 7,\n)\nohlcv_g2 = _make_ohlcv(dates, close_vals=[10.0] * 10)\nohlcv_sell1 = {\"sh.600007\": ohlcv_g, \"sh.600008\": ohlcv_g2}\nenv_s1, info_s1, shares_s1 = _sell_test(ohlcv_sell1, \"sh.600007\", \"limit-down\")\nblocked_s1 = [t for t in info_s1.get(\"blocked_trades\", []) if t[\"symbol\"] == \"sh.600007\"]\nassert len(blocked_s1) > 0, \"Limit-down sell should be blocked\"\nassert \"sh.600007\" in env_s1._holdings, \"Position should be kept\"\nassert env_s1._holdings[\"sh.600007\"][\"shares\"] == shares_s1, \"Shares should be unchanged\"\nprint(f\"[OK] Limit-down sell blocked: position unchanged, blocked={blocked_s1}\")\n\n# Test: 一字板 blocks sell (O=H=L=C, any direction)\nprev_close_h = 10.0\nyizi_sell_price = prev_close_h * 0.98  # not limit-down, just flat bar\nohlcv_h = _make_ohlcv(\n    dates,\n    close_vals=[prev_close_h, prev_close_h, yizi_sell_price] + [yizi_sell_price] * 7,\n    open_vals=[prev_close_h, prev_close_h, yizi_sell_price] + [yizi_sell_price] * 7,\n)\n# Force O=H=L=C for 一字板 on day 2\nfor col in [\"open\", \"high\", \"low\", \"close\"]:\n    ohlcv_h.iloc[2, ohlcv_h.columns.get_loc(col)] = yizi_sell_price\nohlcv_h2 = _make_ohlcv(dates, close_vals=[10.0] * 10)\nohlcv_sell2 = {\"sh.600009\": ohlcv_h, \"sh.600010\": ohlcv_h2}\nenv_s2, info_s2, shares_s2 = _sell_test(ohlcv_sell2, \"sh.600009\", \"一字板\")\nblocked_s2 = [t for t in info_s2.get(\"blocked_trades\", []) if t[\"symbol\"] == \"sh.600009\"]\nassert len(blocked_s2) > 0, \"一字板 sell should be blocked\"\nassert env_s2._holdings[\"sh.600009\"][\"shares\"] == shares_s2\nprint(f\"[OK] 一字板 sell blocked: position unchanged, blocked={blocked_s2}\")\n\n# Test: suspended (volume=0) blocks sell\nohlcv_j = _make_ohlcv(\n    dates,\n    close_vals=[10.0] * 10,\n    volume_vals=[10000, 10000, 0] + [0] * 7,\n)\nohlcv_j2 = _make_ohlcv(dates, close_vals=[10.0] * 10)\nohlcv_sell3 = {\"sh.600011\": ohlcv_j, \"sh.600012\": ohlcv_j2}\nenv_s3, info_s3, shares_s3 = _sell_test(ohlcv_sell3, \"sh.600011\", \"suspension\")\nblocked_s3 = [t for t in info_s3.get(\"blocked_trades\", []) if t[\"symbol\"] == \"sh.600011\"]\nassert len(blocked_s3) > 0, \"Suspension sell should be blocked\"\nassert env_s3._holdings[\"sh.600011\"][\"shares\"] == shares_s3\nprint(f\"[OK] Suspension sell blocked: position unchanged, blocked={blocked_s3}\")\n\n# ══════════════════════════════════════════════════════════════════\n# T+1 MASK TEST: can't sell stock bought today\n# ══════════════════════════════════════════════════════════════════\nprint(\"\\n\" + \"=\" * 60)\nprint(\"T+1 MASK TEST\")\nprint(\"=\" * 60)\n\nohlcv_k = _make_ohlcv(dates, close_vals=[10.0] * 10)\nohlcv_l = _make_ohlcv(dates, close_vals=[10.0] * 10)\nohlcv_m = _make_ohlcv(dates, close_vals=[10.0] * 10)\nohlcv_t1 = {\"sh.600013\": ohlcv_k, \"sh.600014\": ohlcv_l, \"sh.600015\": ohlcv_m}\nranking_t1 = list(ohlcv_t1.keys())\nsigs_t1 = _make_signals(dates, ranking_t1, ranking=ranking_t1)\n\nenv_t1 = PortfolioEnv(test_cfg, sigs_t1, ohlcv_t1, bench_df, training_mode=False)\nobs_t1, _ = env_t1.reset()\n\n# Buy stock on slot 0\nobs_t1, _, _, _, _ = env_t1.step(act_idx)\nassert \"sh.600013\" in env_t1._holdings or any(\n    s in env_t1._holdings for s in ranking_t1\n), \"Should have bought something\"\n\n# Check action masks: selling the just-bought stock should still be\n# allowed in the mask (hold_days=0 at mask time is fine — after increment\n# it will be 1, meeting the T+1 minimum). The mask doesn't block this\n# because hold_days >= 0 passes. The actual T+1 enforcement is in _can_sell\n# (hold_days < 1 after increment). Since step() increments hold_days BEFORE\n# sells, a stock with hold_days=0 at mask time → 1 after increment → sellable.\n# This confirms the mask is correct: it does NOT over-block.\nmask_t1 = env_t1.action_masks()\nassert mask_t1[sell_act_idx], \"All-zero weight action should be legal\"\nprint(f\"[OK] T+1 mask: sell action remains legal (hold_days=0 at mask time \"\n      f\"→ 1 after increment → sellable)\")\n\n# Verify: if we manually set hold_days to -1 (hypothetical), mask still\n# doesn't block (mask only checks hold_days < 0, which is a safety net).\n# The real T+1 enforcement is in _can_sell during step().\nprint(f\"[OK] T+1 enforced by _can_sell (hold_days < 1), not by mask\")\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"=== All illegal-action tests passed ===\")\nprint(\"=\" * 60)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 7: Run RL backtest\nimport time\nfrom screener.backtester import WalkForwardBacktester\n\nbt = WalkForwardBacktester(cfg)\n\nt0 = time.time()\nrl_results = bt.run_rl(verbose=True)\nrl_elapsed = time.time() - t0\n\nprint(f'\\nRL backtest wall time: {rl_elapsed/60:.1f} min')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 7: Display RL results\nimport matplotlib.pyplot as plt\n\nprint('=== RL Backtest Metrics ===')\nfor k, v in rl_results['metrics'].items():\n    print(f'  {k:>20}: {v:.4f}' if isinstance(v, float) else f'  {k:>20}: {v}')\n\nprint('\\n=== Per-Window Results ===')\nfor wr in rl_results['window_results']:\n    print(f\"  Window {wr['window']+1}: {wr['test_start']}→{wr['test_end']}  \"\n          f\"return={wr['test_return']*100:+.2f}%  NAV={wr['final_nav']:,.0f}  \"\n          f\"blocked={wr['blocked_trades']}  subs={wr.get('substituted_trades', 0)}\")\n\n# NAV curve comparison\nfig, ax = plt.subplots(figsize=(14, 5))\nrl_nav = rl_results['nav_series']\nif len(rl_nav) > 0:\n    (rl_nav / rl_nav.iloc[0]).plot(ax=ax, label='RL Agent', linewidth=1.5)\n\n# Overlay paper trader NAV if available\nif 'results' in dir() and 'nav_series' in results:\n    pt_nav = results['nav_series']\n    if len(pt_nav) > 0:\n        (pt_nav / pt_nav.iloc[0]).plot(ax=ax, label='Paper Trader', linewidth=1, alpha=0.7)\n\nax.set_title('Normalised NAV: RL Agent vs Paper Trader')\nax.set_ylabel('Growth of $1')\nax.legend()\nax.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.show()\n\n# Save RL results\nimport pickle\nrl_path = os.path.join(cfg.run_dir, 'rl_backtest_results.pkl')\nos.makedirs(os.path.dirname(rl_path), exist_ok=True)\nwith open(rl_path, 'wb') as f:\n    pickle.dump(rl_results, f)\nprint(f'\\nRL results saved → {rl_path}')"
  },
  {
   "cell_type": "markdown",
   "source": "## RL Ablation: Candidate Mode × Action Mode\n\nRuns 6 variants to verify that L2 screening and the RL policy each contribute value.\n\n| Label | candidate_mode | action_mode | What it tests |\n|-------|---------------|-------------|---------------|\n| A (baseline) | top | policy | Current RL agent |\n| B | random_l2 | policy | Does rank within top 30 matter? |\n| C | bottom_l2 | policy | Does L2 ordering matter? |\n| D | random_l1 | policy | Does L2 filtering matter? |\n| E | top | equal_weight | Does RL policy add value over naive? |\n| F | top | random | Does learned policy beat random? |\n\n**Expected ordering (if system works):** A > B > C, A > D, A > E, A > F",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Cell 8: RL Ablation — candidate mode × action mode\n# Reuses trained PPO models from Cell 7. For random/equal_weight action modes,\n# no model is loaded. All variants use inference_only=True.\n\nimport time\nimport pandas as pd\nfrom screener.backtester import WalkForwardBacktester\n\nABLATION_VARIANTS = [\n    (\"A (baseline)\",  \"top\",       \"policy\"),\n    (\"B (rand L2)\",   \"random_l2\", \"policy\"),\n    (\"C (bottom L2)\", \"bottom_l2\", \"policy\"),\n    (\"D (rand L1)\",   \"random_l1\", \"policy\"),\n    (\"E (equal wt)\",  \"top\",       \"equal_weight\"),\n    (\"F (random)\",    \"top\",       \"random\"),\n]\n\nablation_rows = []\nablation_navs = {}\n\nfor label, cand_mode, act_mode in ABLATION_VARIANTS:\n    print(f\"\\n{'='*60}\")\n    print(f\"  Ablation: {label}  (candidate={cand_mode}, action={act_mode})\")\n    print(f\"{'='*60}\")\n\n    abl_bt = WalkForwardBacktester(cfg)\n    t0 = time.time()\n    res = abl_bt.run_rl(\n        verbose=False,\n        inference_only=True,\n        candidate_mode=cand_mode,\n        action_mode=act_mode,\n    )\n    elapsed = time.time() - t0\n\n    m = res[\"metrics\"]\n    ablation_rows.append({\n        \"variant\": label,\n        \"candidate_mode\": cand_mode,\n        \"action_mode\": act_mode,\n        \"total_return\": m.get(\"total_return\", 0.0),\n        \"sharpe\": m.get(\"sharpe\", 0.0),\n        \"max_drawdown\": m.get(\"max_drawdown\", 0.0),\n        \"wall_time_s\": elapsed,\n    })\n    ablation_navs[label] = res[\"nav_series\"]\n    print(f\"  Return: {m.get('total_return', 0):.4f}  \"\n          f\"Sharpe: {m.get('sharpe', 0):.4f}  \"\n          f\"MaxDD: {m.get('max_drawdown', 0):.4f}  \"\n          f\"({elapsed:.0f}s)\")\n\n# ── Summary table ─────────────────────────────────────────────────\nprint(f\"\\n{'='*60}\")\nprint(\"ABLATION SUMMARY\")\nprint(f\"{'='*60}\")\nabl_df = pd.DataFrame(ablation_rows)\nabl_df = abl_df.set_index(\"variant\")\nprint(abl_df[[\"candidate_mode\", \"action_mode\", \"total_return\", \"sharpe\", \"max_drawdown\"]].to_string())\n\n# ── NAV curves ────────────────────────────────────────────────────\nimport matplotlib.pyplot as plt\n\nfig, ax = plt.subplots(figsize=(14, 5))\nfor label, nav in ablation_navs.items():\n    if len(nav) > 0:\n        (nav / nav.iloc[0]).plot(ax=ax, label=label, linewidth=1.2)\nax.set_title(\"RL Ablation: Normalised NAV\")\nax.set_ylabel(\"Growth of $1\")\nax.legend(fontsize=9)\nax.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: List past runs\n",
    "runs_dir = os.path.join(cfg.drive_root, 'runs')\n",
    "if os.path.isdir(runs_dir):\n",
    "    runs = sorted(os.listdir(runs_dir), reverse=True)\n",
    "    print(f'Past runs ({len(runs)}):')\n",
    "    for r in runs:\n",
    "        run_path = os.path.join(runs_dir, r)\n",
    "        contents = os.listdir(run_path)\n",
    "        print(f'  {r}  ({\", \".join(sorted(contents))})')\n",
    "else:\n",
    "    print('No runs yet.')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}