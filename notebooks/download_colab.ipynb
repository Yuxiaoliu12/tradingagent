{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "!pip install baostock -q"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "from google.colab import drive\ndrive.mount('/content/drive')\n\nimport os\nSAVE_DIR = '/content/drive/MyDrive/kronos/data'\nos.makedirs(SAVE_DIR, exist_ok=True)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import os, time, pickle\n",
    "import baostock as bs\n",
    "import pandas as pd\n",
    "\n",
    "def save_pickle(data, path):\n",
    "    tmp = path + '.tmp'\n",
    "    with open(tmp, 'wb') as f:\n",
    "        pickle.dump(data, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    os.replace(tmp, path)\n",
    "\n",
    "def load_pickle(path):\n",
    "    if os.path.exists(path):\n",
    "        with open(path, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "    return {}\n",
    "\n",
    "lg = bs.login()\n",
    "print(f'baostock login: {lg.error_msg}')"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Get all A-share stock codes\n",
    "rs = bs.query_all_stock(day='2026-02-25')\n",
    "all_stocks = rs.get_data()\n",
    "\n",
    "# Filter to A-shares only: sh.6xxxxx, sz.0xxxxx, sz.3xxxxx\n",
    "mask = all_stocks['code'].str.match(r'^(sh\\.6|sz\\.0|sz\\.3)')\n",
    "symbols = all_stocks[mask]['code'].tolist()\n",
    "print(f'Found {len(symbols)} A-share stocks')\n",
    "print(f'Examples: {symbols[:5]}')"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# === TEST: download first 5 stocks ===\n",
    "# Change symbols[:5] to `symbols` for the full run.\n",
    "\n",
    "SAVE_PATH = f'{SAVE_DIR}/ohlcv_all_a.pkl'\n",
    "START = '2015-01-01'\n",
    "END   = '2026-02-26'\n",
    "FIELDS = 'date,open,high,low,close,volume,amount'\n",
    "\n",
    "data = load_pickle(SAVE_PATH)\n",
    "if data:\n",
    "    print(f'Resuming: {len(data)} stocks already downloaded')\n",
    "\n",
    "batch = symbols[:5]  # <-- change to `symbols` for full download\n",
    "total = len(batch)\n",
    "\n",
    "for i, code in enumerate(batch, 1):\n",
    "    if code in data:\n",
    "        continue\n",
    "    try:\n",
    "        rs = bs.query_history_k_data_plus(\n",
    "            code=code, fields=FIELDS,\n",
    "            start_date=START, end_date=END,\n",
    "            frequency='d', adjustflag='2',  # qfq\n",
    "        )\n",
    "        rows = []\n",
    "        while (rs.error_code == '0') & rs.next():\n",
    "            rows.append(rs.get_row_data())\n",
    "        if not rows:\n",
    "            print(f'[{i}/{total}] {code} — empty')\n",
    "            continue\n",
    "        df = pd.DataFrame(rows, columns=rs.fields)\n",
    "        for col in ['open','high','low','close','volume','amount']:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "        df = df.set_index('date')\n",
    "        data[code] = df\n",
    "        rng = f'{df.index.min().date()} to {df.index.max().date()}'\n",
    "        print(f'[{i}/{total}] {code} — {len(df)} rows ({rng})')\n",
    "    except Exception as e:\n",
    "        print(f'[{i}/{total}] {code} — FAILED: {e}')\n",
    "\n",
    "    if len(data) % 100 == 0 and len(data) > 0:\n",
    "        save_pickle(data, SAVE_PATH)\n",
    "        print(f'  ** checkpoint ({len(data)} stocks) **')\n",
    "\n",
    "save_pickle(data, SAVE_PATH)\n",
    "print(f'\\nDone. {len(data)} stocks saved to {SAVE_PATH}')"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Download CSI500 benchmark (sh.000905)\n",
    "rs = bs.query_history_k_data_plus(\n",
    "    code='sh.000905', fields='date,open,high,low,close,volume,amount',\n",
    "    start_date='2015-01-01', end_date='2026-02-26',\n",
    "    frequency='d',\n",
    ")\n",
    "rows = []\n",
    "while (rs.error_code == '0') & rs.next():\n",
    "    rows.append(rs.get_row_data())\n",
    "bench = pd.DataFrame(rows, columns=rs.fields)\n",
    "for col in ['open','high','low','close','volume','amount']:\n",
    "    bench[col] = pd.to_numeric(bench[col], errors='coerce')\n",
    "bench['date'] = pd.to_datetime(bench['date'])\n",
    "bench = bench.set_index('date')\n",
    "\n",
    "bench_path = f'{SAVE_DIR}/benchmark_000905.pkl'\n",
    "save_pickle(bench, bench_path)\n",
    "print(f'Benchmark CSI500: {len(bench)} rows saved to {bench_path}')"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "bs.logout()\n",
    "\n",
    "# Verify\n",
    "check = load_pickle(f'{SAVE_DIR}/ohlcv_all_a.pkl')\n",
    "print(f'Stocks in pickle: {len(check)}')\n",
    "for sym, df in list(check.items())[:3]:\n",
    "    print(f'  {sym}: {df.shape}, cols={list(df.columns)}, '\n",
    "          f'dtypes=[{df[\"close\"].dtype}]')"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ]
}