{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# RL Agent — Single Window Debug Run\n\nRuns **1 walk-forward window** (train: 2016-2017, test: 2018-Q1) to validate\nthe full pipeline before committing to the 32-window backtest.\n\n**Algorithm:** MaskablePPO (sb3-contrib) with action masking, normalised observations.\n\n**Runtime:** T4 GPU"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 1: Setup\nimport warnings\nwarnings.filterwarnings('ignore', module='jupyter_client')\nwarnings.filterwarnings('ignore', message='.*Gym has been unmaintained.*')\nwarnings.filterwarnings('ignore', message='.*Falling back to prediction using DMatrix.*')\n\nfrom google.colab import drive\ndrive.mount('/content/drive')\n\nimport os, sys\nDRIVE_ROOT = '/content/drive/MyDrive/kronos'\nREPO_DIR = '/content/tradingagent'\n\nif not os.path.exists(REPO_DIR):\n    !git clone https://github.com/Yuxiaoliu12/tradingagent.git {REPO_DIR}\n\n!pip install -q -r {REPO_DIR}/requirements.txt\n\nsys.path.insert(0, REPO_DIR)\nprint(f'Repo: {REPO_DIR}')\nprint(f'Drive: {DRIVE_ROOT}')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 2: Smoke test (synthetic data, no L1+L2 needed)\nimport numpy as np\nimport pandas as pd\nfrom screener.portfolio_env import build_action_table, PortfolioEnv\nfrom screener.rl_trader import RLTrader\nfrom screener.config import ScreenerConfig\n\n# Action table\nactions = build_action_table(3, 3)\nassert len(actions) == 63, f'Expected 63 actions, got {len(actions)}'\nprint(f'[OK] Action table: {len(actions)} actions')\n\n# Synthetic env\nnp.random.seed(42)\nn_days, n_stocks = 100, 50\ndates = pd.bdate_range('2020-01-01', periods=n_days)\nohlcv_dict = {}\nfor i in range(n_stocks):\n    sym = f'sh.{600000+i}'\n    close = 10.0 * np.exp(np.cumsum(np.random.randn(n_days) * 0.02))\n    ohlcv_dict[sym] = pd.DataFrame({\n        'open': close * (1 + np.random.randn(n_days) * 0.005),\n        'high': close * (1 + abs(np.random.randn(n_days) * 0.01)),\n        'low':  close * (1 - abs(np.random.randn(n_days) * 0.01)),\n        'close': close,\n        'volume': np.random.randint(1000, 100000, n_days).astype(float),\n    }, index=dates)\n\nsymbols = list(ohlcv_dict.keys())\nbench_df = pd.DataFrame({'close': np.linspace(100, 110, n_days)}, index=dates)\ndaily_signals = []\nfor d in dates:\n    upside = pd.Series(np.abs(np.random.randn(n_stocks)) * 0.05, index=symbols)\n    downside = pd.Series(-np.abs(np.random.randn(n_stocks)) * 0.05, index=symbols)\n    combined = upside + downside\n    feats = pd.DataFrame(\n        np.random.randn(n_stocks, 15), index=symbols,\n        columns=['macd','macd_signal','macd_hist','rsi_14','rsi_5',\n                 'ma5_slope','ma20_slope','ma60_slope','bb_position',\n                 'volume_trend','mom_5','mom_10','mom_20','atr_14','obv_slope'],\n    )\n    daily_signals.append({\n        'date': d,\n        'l2_scores': combined.sort_values(ascending=False),\n        'l2_upside': upside,\n        'l2_downside': downside,\n        'l2_ranking': list(combined.sort_values(ascending=False).index),\n        'l2_features': feats,\n    })\n\nsmoke_cfg = ScreenerConfig()\n\n# ── 1. Random steps ──\nenv = PortfolioEnv(smoke_cfg, daily_signals, ohlcv_dict, bench_df, training_mode=True)\nobs, _ = env.reset()\nassert obs.shape == (40,) and not np.any(np.isnan(obs))\nfor step in range(n_days - 1):\n    obs, reward, terminated, truncated, info = env.step(env.action_space.sample())\n    assert not np.any(np.isnan(obs)), f'Step {step}: NaN'\n    if terminated: break\nprint(f'[OK] Random agent: {step+1} steps, NAV={env._nav:,.0f} ({env._nav/smoke_cfg.initial_capital-1:+.2%})')\n\n# ── 2. Action mask sanity ──\nenv2 = PortfolioEnv(smoke_cfg, daily_signals, ohlcv_dict, bench_df, training_mode=False)\nobs2, _ = env2.reset()\nmask = env2.action_masks()\nassert mask.shape == (63,), f'Mask shape: {mask.shape}'\nassert mask.dtype == bool\nassert mask.any(), 'All actions masked!'\nn_masked = (~mask).sum()\nprint(f'[OK] Action masks: {mask.sum()}/63 legal, {n_masked} masked (day 0)')\n\n# Step a few times and verify masks update\nfor _ in range(5):\n    legal_actions = np.where(mask)[0]\n    act = np.random.choice(legal_actions)\n    obs2, _, term, _, _ = env2.step(act)\n    if term: break\n    mask = env2.action_masks()\n    assert mask.any()\nprint(f'[OK] Action masks update correctly across steps')\n\n# ── 3. MaskablePPO train 1000 steps ──\nsmoke_cfg_ppo = ScreenerConfig(rl_total_timesteps=1000, rl_batch_size=32, rl_n_steps=128)\ntrain_env = PortfolioEnv(smoke_cfg_ppo, daily_signals, ohlcv_dict, bench_df, training_mode=True)\ntrader = RLTrader(smoke_cfg_ppo)\nmodel = trader.train(train_env)\n\n# ── 4. Inference with masks ──\nfrom sb3_contrib.common.wrappers import ActionMasker\nfrom sb3_contrib.common.maskable.utils import get_action_masks\n\ntest_env = PortfolioEnv(smoke_cfg_ppo, daily_signals, ohlcv_dict, bench_df, training_mode=False)\nmasked_test_env = ActionMasker(test_env, lambda e: e.action_masks())\nobs, _ = masked_test_env.reset()\nblocked_total = 0\nfor _ in range(20):\n    masks = get_action_masks(masked_test_env)\n    action, _ = model.predict(obs, deterministic=True, action_masks=masks)\n    obs, reward, terminated, truncated, info = masked_test_env.step(int(action))\n    blocked_total += len(info.get('blocked_trades', []))\n    if terminated: break\nprint(f'[OK] PPO inference: NAV={test_env._nav:,.0f}, blocked_trades={blocked_total}')\n\n# ── 5. Save/load ──\nimport tempfile\nwith tempfile.TemporaryDirectory() as tmpdir:\n    p = os.path.join(tmpdir, 'smoke')\n    trader.save(model, p)\n    loaded = trader.load(p)\n    obs_t, _ = masked_test_env.reset()\n    masks_t = get_action_masks(masked_test_env)\n    a1, _ = model.predict(obs_t, deterministic=True, action_masks=masks_t)\n    a2, _ = loaded.predict(obs_t, deterministic=True, action_masks=masks_t)\n    assert a1 == a2\nprint('[OK] Save/load round-trip')\nprint('\\n=== All smoke tests passed ===')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Config — 1 window only (test 2018-Q1)\n",
    "from screener.config import ScreenerConfig\n",
    "\n",
    "cfg = ScreenerConfig(\n",
    "    ohlcv_pickle_path=os.path.join(DRIVE_ROOT, 'data/ohlcv_all_a.pkl'),\n",
    "    benchmark_pickle_path=os.path.join(DRIVE_ROOT, 'data/benchmark_000905.pkl'),\n",
    "    drive_root=os.path.join(DRIVE_ROOT, 'output/screener'),\n",
    "    backtest_end='2018-03-31',   # <-- 1 window only\n",
    ")\n",
    "\n",
    "cfg.layer1_xgb_params['device'] = 'cuda'\n",
    "cfg.layer2_xgb_params['device'] = 'cuda'\n",
    "\n",
    "print(f'Train: {cfg.train_start} -> {cfg.train_end}')\n",
    "print(f'Backtest: {cfg.backtest_start} -> {cfg.backtest_end}')\n",
    "print(f'Run ID: {cfg.run_id}')\n",
    "print(f'Cache dir: {cfg.cache_dir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Run RL backtest (1 window)\n",
    "import time\n",
    "from screener.backtester import WalkForwardBacktester\n",
    "\n",
    "bt = WalkForwardBacktester(cfg)\n",
    "\n",
    "t0 = time.time()\n",
    "rl_results = bt.run_rl(verbose=True)\n",
    "elapsed = time.time() - t0\n",
    "\n",
    "print(f'\\nWall time: {elapsed/60:.1f} min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print('=== Metrics ===')\n",
    "for k, v in rl_results['metrics'].items():\n",
    "    print(f'  {k:>20}: {v:.4f}' if isinstance(v, float) else f'  {k:>20}: {v}')\n",
    "\n",
    "print('\\n=== Window Results ===')\n",
    "for wr in rl_results['window_results']:\n",
    "    print(f\"  Window {wr['window']+1}: {wr['test_start']}->{wr['test_end']}  \"\n",
    "          f\"return={wr['test_return']*100:+.2f}%  NAV={wr['final_nav']:,.0f}  \"\n",
    "          f\"blocked={wr['blocked_trades']}\")\n",
    "\n",
    "# NAV curve\n",
    "rl_nav = rl_results['nav_series']\n",
    "if len(rl_nav) > 0:\n",
    "    fig, ax = plt.subplots(figsize=(12, 4))\n",
    "    rl_nav.plot(ax=ax, title='RL Agent NAV (Window 1)', linewidth=1.5)\n",
    "    ax.set_ylabel('NAV')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Save\n",
    "import pickle\n",
    "rl_path = os.path.join(cfg.run_dir, 'rl_backtest_results.pkl')\n",
    "os.makedirs(os.path.dirname(rl_path), exist_ok=True)\n",
    "with open(rl_path, 'wb') as f:\n",
    "    pickle.dump(rl_results, f)\n",
    "print(f'\\nResults saved -> {rl_path}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}